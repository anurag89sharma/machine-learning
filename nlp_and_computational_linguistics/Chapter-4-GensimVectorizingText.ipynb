{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Transformation in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [u\"Football club Arsenal defeat local rivals this weekend.\", \n",
    "             u\"Weekend football frenzy takes over London.\", \n",
    "             u\"Bank open for take over bids after losing millions.\", \n",
    "             u\"London football clubs bid to move to Wembley stadium.\", \n",
    "             u\"Arsenal bid 50 million pounds for striker Kane.\", \n",
    "             u\"Financial troubles result in loss of millions for bank.\", \n",
    "             u\"Western bank files for bankruptcy after financial losses.\", \n",
    "             u\"London football club is taken over by oil millionaire from Russia.\", \n",
    "             u\"Banking on finances not working for Russia.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['football', 'club', 'arsenal', 'defeat', 'local', 'rival', 'weekend'],\n",
      " ['weekend', 'football', 'frenzy', 'take', 'london'],\n",
      " ['bank', 'open', 'bid', 'lose', 'million'],\n",
      " ['london', 'football', 'club', 'bid', 'wembley', 'stadium'],\n",
      " ['arsenal', 'bid', 'pound', 'striker', 'kane'],\n",
      " ['financial', 'trouble', 'result', 'loss', 'million', 'bank'],\n",
      " ['western', 'bank', 'file', 'bankruptcy', 'financial', 'loss'],\n",
      " ['london', 'football', 'club', 'take', 'oil', 'millionaire', 'russia'],\n",
      " ['bank', 'finance', 'work', 'russia']]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en\")\n",
    "texts = []\n",
    "\n",
    "for document in documents:\n",
    "    text = []\n",
    "    doc = nlp(document)\n",
    "    for w in doc:\n",
    "        if not w.is_stop and not w.is_punct and not w.like_num:\n",
    "            text.append(w.lemma_)\n",
    "    texts.append(text)\n",
    "    \n",
    "pprint(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-words representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arsenal': 0, 'club': 1, 'defeat': 2, 'football': 3, 'local': 4, 'rival': 5, 'weekend': 6, 'frenzy': 7, 'london': 8, 'take': 9, 'bank': 10, 'bid': 11, 'lose': 12, 'million': 13, 'open': 14, 'stadium': 15, 'wembley': 16, 'kane': 17, 'pound': 18, 'striker': 19, 'financial': 20, 'loss': 21, 'result': 22, 'trouble': 23, 'bankruptcy': 24, 'file': 25, 'western': 26, 'millionaire': 27, 'oil': 28, 'russia': 29, 'finance': 30, 'work': 31}\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert `document` into the bag-of-words (BoW) format = list of `(token_id, token_count)` tuples.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        document : list of str\n",
      "            Input document.\n",
      "        allow_update : bool, optional\n",
      "            Update self, by adding new tokens from `document` and updating internal corpus statistics.\n",
      "        return_missing : bool, optional\n",
      "            Return missing tokens (tokens present in `document` but not in self) with frequencies?\n",
      "\n",
      "        Return\n",
      "        ------\n",
      "        list of (int, int)\n",
      "            BoW representation of `document`.\n",
      "        list of (int, int), dict of (str, int)\n",
      "            If `return_missing` is True, return BoW representation of `document` + dictionary with missing\n",
      "            tokens and their frequencies.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from gensim.corpora import Dictionary\n",
      "        >>> dct = Dictionary([\"máma mele maso\".split(), \"ema má máma\".split()])\n",
      "        >>> dct.doc2bow([\"this\", \"is\", \"máma\"])\n",
      "        [(2, 1)]\n",
      "        >>> dct.doc2bow([\"this\", \"is\", \"máma\"], return_missing=True)\n",
      "        ([(2, 1)], {u'this': 1, u'is': 1})\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(dictionary.doc2bow.__doc__)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(3, 1), (6, 1), (7, 1), (8, 1), (9, 1)], [(10, 1), (11, 1), (12, 1), (13, 1), (14, 1)], [(1, 1), (3, 1), (8, 1), (11, 1), (15, 1), (16, 1)], [(0, 1), (11, 1), (17, 1), (18, 1), (19, 1)], [(10, 1), (13, 1), (20, 1), (21, 1), (22, 1), (23, 1)], [(10, 1), (20, 1), (21, 1), (24, 1), (25, 1), (26, 1)], [(1, 1), (3, 1), (8, 1), (9, 1), (27, 1), (28, 1), (29, 1)], [(10, 1), (29, 1), (30, 1), (31, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert `document` (a list of words) into a list of indexes = list of `token_id`.\n",
      "        Replace all unknown words i.e, words not in the dictionary with the index as set via `unknown_word_index`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        document : list of str\n",
      "            Input document\n",
      "        unknown_word_index : int, optional\n",
      "            Index to use for words not in the dictionary.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of int\n",
      "            Token ids for tokens in `document`, in the same order.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from gensim.corpora import Dictionary\n",
      "        >>>\n",
      "        >>> corpus = [[\"a\", \"a\", \"b\"], [\"a\", \"c\"]]\n",
      "        >>> dct = Dictionary(corpus)\n",
      "        >>> dct.doc2idx([\"a\", \"a\", \"c\", \"not_in_dictionary\", \"c\"])\n",
      "        [0, 0, 2, -1, 2]\n",
      "\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3, 1, 0, 2, 4, 5, 6],\n",
       " [6, 3, 7, 9, 8],\n",
       " [10, 14, 11, 12, 13],\n",
       " [8, 3, 1, 11, 16, 15],\n",
       " [0, 11, 18, 19, 17],\n",
       " [20, 23, 22, 21, 13, 10],\n",
       " [26, 10, 25, 24, 20, 21],\n",
       " [8, 3, 1, 9, 28, 27, 29],\n",
       " [10, 30, 31, 29]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dictionary.doc2idx.__doc__)\n",
    "[dictionary.doc2idx(x) for x in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('top_corpus.mm', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words to TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.3292179861221233), (1, 0.24046829370585296), (2, 0.4809365874117059), (3, 0.1774993848325406), (4, 0.4809365874117059), (5, 0.4809365874117059), (6, 0.3292179861221233)]\n",
      "[(3, 0.24212967666975266), (6, 0.4490913847888623), (7, 0.6560530929079719), (8, 0.32802654645398593), (9, 0.4490913847888623)]\n",
      "[(10, 0.2184344336379748), (11, 0.29592528218102643), (12, 0.5918505643620529), (13, 0.4051424990000138), (14, 0.5918505643620529)]\n",
      "[(1, 0.29431054749542984), (3, 0.21724253258131512), (8, 0.29431054749542984), (11, 0.29431054749542984), (15, 0.5886210949908597), (16, 0.5886210949908597)]\n",
      "[(0, 0.354982288765831), (11, 0.25928712547209604), (17, 0.5185742509441921), (18, 0.5185742509441921), (19, 0.5185742509441921)]\n",
      "[(10, 0.19610384738673725), (13, 0.3637247180792822), (20, 0.3637247180792822), (21, 0.3637247180792822), (22, 0.5313455887718271), (23, 0.5313455887718271)]\n",
      "[(10, 0.18286519950508276), (20, 0.3391702611796705), (21, 0.3391702611796705), (24, 0.4954753228542582), (25, 0.4954753228542582), (26, 0.4954753228542582)]\n",
      "[(1, 0.2645025265769199), (3, 0.1952400253294319), (8, 0.2645025265769199), (9, 0.3621225392416359), (27, 0.5290050531538398), (28, 0.5290050531538398), (29, 0.3621225392416359)]\n",
      "[(10, 0.22867660961662029), (29, 0.4241392327204109), (30, 0.6196018558242014), (31, 0.6196018558242014)]\n"
     ]
    }
   ],
   "source": [
    "for document in tfidf[corpus]:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['football', 'club', 'arsenal', 'defeat', 'local', 'rival', 'weekend'],\n",
      " ['weekend', 'football', 'frenzy', 'take', 'london'],\n",
      " ['bank', 'open', 'bid', 'lose', 'million'],\n",
      " ['london', 'football', 'club', 'bid', 'wembley', 'stadium'],\n",
      " ['arsenal', 'bid', 'pound', 'striker', 'kane'],\n",
      " ['financial', 'trouble', 'result', 'loss', 'million', 'bank'],\n",
      " ['western', 'bank', 'file', 'bankruptcy', 'financial', 'loss'],\n",
      " ['london', 'football', 'club', 'take', 'oil', 'millionaire', 'russia'],\n",
      " ['bank', 'finance', 'work', 'russia']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimension/.virtualenvs/data-science/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "bigram = models.Phrases(texts)\n",
    "bigrams_texts = [bigram[line] for line in texts]\n",
    "\n",
    "pprint(bigrams_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_dictionary = corpora.Dictionary(bigrams_texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in bigrams_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)],\n",
      " [(3, 1), (6, 1), (7, 1), (8, 1), (9, 1)],\n",
      " [(10, 1), (11, 1), (12, 1), (13, 1), (14, 1)],\n",
      " [(1, 1), (3, 1), (8, 1), (11, 1), (15, 1), (16, 1)],\n",
      " [(0, 1), (11, 1), (17, 1), (18, 1), (19, 1)],\n",
      " [(10, 1), (13, 1), (20, 1), (21, 1), (22, 1), (23, 1)],\n",
      " [(10, 1), (20, 1), (21, 1), (24, 1), (25, 1), (26, 1)],\n",
      " [(1, 1), (3, 1), (8, 1), (9, 1), (27, 1), (28, 1), (29, 1)],\n",
      " [(10, 1), (29, 1), (30, 1), (31, 1)]]\n"
     ]
    }
   ],
   "source": [
    "pprint(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
